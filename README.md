# ğŸ¤—ì†Œê°œğŸ¤—(Course Introduction) <sub>-ì œì‘ì:ì •ì¬ì—°-<sub>

 ì´ ë ˆíŒŒì§€í† ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ì„ ê¹Šì´ ìˆê²Œ ë‹¤ë£¨ë©°, ë…¼ë¬¸ ë¦¬ë·° ë° ì½”ë“œ êµ¬í˜„ì„ í†µí•´ ì‹¤ì§ˆì ì¸ ì´í•´ë¥¼ ëª©í‘œë¡œí•©ë‹ˆë‹¤.

í•¨ê»˜ ì§„í–‰í•˜ëŠ” ì´ ê°•ì˜ì—ì„œëŠ” ì „í†µì ì¸ ë”¥ëŸ°ë‹ ì´ë¡ ë¶€í„° ìµœì‹  ì²˜ë¦¬ ê¸°ìˆ ê³¼ ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  ì½”ë“œëŠ” <footnotesize><strong style="color:#ED5466">PyTorch</strong></footnotesize>ë¡œ ì œì‘ë˜ì—ˆìœ¼ë©°, ì‹¤ìŠµ ë°ì´í„°ë¥¼ í†µí•´ ì§ì ‘ ì‹¤í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë…¼ë¬¸ê³¼ì˜ ì—°ê´€ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

íŠ¹íˆ, ì´ ë ˆíŒŒì§€í† ë¦¬ëŠ” ì „ë¬¸ê°€ê°€ ë˜ê³ ì í•˜ëŠ” ë¶„ë“¤, ì¸ê³µì§€ëŠ¥ì— ê´€ì‹¬ì´ ë§ê³  ëŒ€í•™ì› ì§„í•™ì„ ëª©í‘œë¡œ ê¹Šì´ ìˆëŠ” ê³µë¶€ë¥¼ ì›í•˜ëŠ” ë¶„ë“¤ì—ê²Œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì´ ì „ë¬¸ê°€ë¡œ ì„±ì¥í•  ìˆ˜ ìˆë„ë¡, ìµœì‹  ì—°êµ¬ì™€ ì‹¤ìŠµì„ í†µí•´ ê¹Šì´ ìˆëŠ” í•™ìŠµ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.


# ğŸš€ ë‹¤ì–‘í•œ ë„êµ¬ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬

ì´ ê°•ì˜ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ **í•µì‹¬ ë„êµ¬ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.

## ğŸ”¹ ê°œë°œ í™˜ê²½ ë° ì‹¤í—˜ ê´€ë¦¬ ë„êµ¬  

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white) | **ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ê°€ìƒ í™˜ê²½**ì„ í†µí•´ ì¼ê´€ëœ ê°œë°œ í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤. |
| ![mlflow](https://img.shields.io/badge/mlflow-%23d9ead3.svg?style=for-the-badge&logo=numpy&logoColor=blue) | ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ê´€ë¦¬ ë° ë°°í¬ë¥¼ ì§€ì›í•˜ëŠ” **ì˜¤í”ˆ ì†ŒìŠ¤ í”Œë«í¼**ì…ë‹ˆë‹¤. |
| ![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white) | **ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”ë¥¼ ìœ„í•œ ëŒ€í™”í˜• ë…¸íŠ¸ë¶ í™˜ê²½**ì„ ì œê³µí•©ë‹ˆë‹¤. |

---

## ğŸ”¹ ë¨¸ì‹ ëŸ¬ë‹ ë° MLOps ë„êµ¬  

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| ![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FF4F00?style=for-the-badge&logo=Hugging%20Face&logoColor=white) | ë‹¤ì–‘í•œ **NLP ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ì œê³µí•˜ëŠ” í”Œë«í¼**ì…ë‹ˆë‹¤. |
| ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white) | **ë°ì´í„° íŒŒì´í”„ë¼ì¸ì˜ ìŠ¤ì¼€ì¤„ë§ ë° ëª¨ë‹ˆí„°ë§**ì„ ìœ„í•œ í”Œë«í¼ì…ë‹ˆë‹¤. |
| ![Kubeflow](https://img.shields.io/badge/Kubeflow-0F4F5B?style=for-the-badge&logo=kubeflow&logoColor=white) | **Kubernetes í™˜ê²½ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”Œë«í¼**ì…ë‹ˆë‹¤. |

---

## ğŸ”¹ ëª¨ë¸ ë°°í¬ ë° ì¸í„°í˜ì´ìŠ¤ ë„êµ¬  

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white) | ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ **ë¹ ë¥´ê²Œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ë³€í™˜**í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. |
| ![Gradio](https://img.shields.io/badge/Gradio-00BFFF?style=for-the-badge&logo=gradio&logoColor=white) | AI ëª¨ë¸ì„ **ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‰½ê²Œ ë°°í¬**í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. |

---

## ğŸ”¹ ë°ì´í„° ë° ëª¨ë¸ ë²„ì „ ê´€ë¦¬  

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| ![DVC](https://img.shields.io/badge/DVC-9B63C8?style=for-the-badge&logo=data%20version%20control&logoColor=white) | **ë°ì´í„°ì™€ ëª¨ë¸ ë²„ì „ì„ ê´€ë¦¬**í•˜ê³  í˜‘ì—…ì„ ì§€ì›í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. |
| ![Metaflow](https://img.shields.io/badge/Metaflow-5F3A65?style=for-the-badge&logo=metaflow&logoColor=white) | **ë°ì´í„° ê³¼í•™ ì‘ì—…ì„ ê´€ë¦¬í•˜ê³  ìë™í™”**í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. |

---

## ğŸ”¹ DevOps ë° CI/CD ë„êµ¬  

| ë„êµ¬ | ì„¤ëª… |
|------|------|
| ![Jenkins](https://img.shields.io/badge/Jenkins-D24939?style=for-the-badge&logo=jenkins&logoColor=white) | ì˜¤í”ˆ ì†ŒìŠ¤ **CI/CD ë„êµ¬**ë¡œ, ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ íŒŒì´í”„ë¼ì¸ì„ ìë™í™”í•©ë‹ˆë‹¤. |
| ![GitLab CI/CD](https://img.shields.io/badge/GitLab%20CI/CD-FCA121?style=for-the-badge&logo=gitlab&logoColor=white) | **GitLabì˜ í†µí•© CI/CD ê¸°ëŠ¥**ìœ¼ë¡œ, ì½”ë“œ ë¹Œë“œ, í…ŒìŠ¤íŠ¸ ë° ë°°í¬ë¥¼ ìë™í™”í•©ë‹ˆë‹¤. |
| ![CircleCI](https://img.shields.io/badge/CircleCI-343434?style=for-the-badge&logo=circleci&logoColor=white) | í´ë¼ìš°ë“œ ê¸°ë°˜ **CI/CD í”Œë«í¼**ìœ¼ë¡œ, ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ë¹Œë“œ ë° ë°°í¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. |
| ![Travis CI](https://img.shields.io/badge/Travis%20CI-3D3D3D?style=for-the-badge&logo=travis-ci&logoColor=white) | **GitHubì™€ í†µí•©ë˜ì–´ ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸ ìë™í™”**ë¥¼ ì§€ì›í•˜ëŠ” CI ë„êµ¬ì…ë‹ˆë‹¤. |
| ![Terraform](https://img.shields.io/badge/Terraform-7D5B3F?style=for-the-badge&logo=terraform&logoColor=white) | **ì¸í”„ë¼ë¥¼ ì½”ë“œë¡œ ì •ì˜í•˜ê³  í”„ë¡œë¹„ì €ë‹**í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. |

---

ğŸ“Œ **ì´ ë¬¸ì„œëŠ” ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.** ğŸ› ï¸  
í•„ìš”í•œ ë„êµ¬ê°€ ìˆë‹¤ë©´ ì¶”ê°€ ìš”ì²­í•´ ì£¼ì„¸ìš”! ğŸ˜Š


## References
<div style="border: 2px solid #ccc; padding: 10px; border-radius: 5px;">
  <h3>NLP(ìì—°ì–´ì²˜ë¦¬)</h3>
  <table>
    <tr>
      <th>ë…¼ë¬¸ ì£¼ì œ</th>
      <th>ë…¼ë¬¸ ì›ë³¸</th>
      <th>ë¦¬ë·° ë° ìš”ì•½</th>
      <th>ì½”ë“œêµ¬í˜„</th>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Bag of Words</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1301.6770">An alternative text representation to TF-IDF and Bag-of-Words</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">TF-IDF</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1301.6770">An alternative text representation to TF-IDF and Bag-of-Words</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">CBOW&SG</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1301.3781">Efficient Estimation of Word Representations in Vector Space</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Embedding</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1901.09069">Word Embeddings: A Survey</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">RNN</span></small></b></td>
      <td><a href="https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf">Learning representations by back-propagation errors</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">LSTM</span></small></b></td>
      <td><a href="https://deeplearning.cs.cmu.edu/S23/document/readings/LSTM.pdf">Long Short-Term Memory</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">seq2seq</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1409.3215">Sequence to Sequence Learning with Neural Networks</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Mamba</span></small></b></td>
      <td></td>
      <td></td>
      <td><a href="https://github.com/alxndrTL/mamba.py">https://github.com/alxndrTL/mamba.py</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Attention RNN</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1911.11423v2">Single Headed Attention RNN: Stop Thinking With Your Head</a></td>
      <td></td>
      <td><a href="https://github.com/Smerity/sha-rnn/blob/218d748022dbcf32d50bbbb4d151a9b6de3f8bba/model.py#L53">https://github.com/Smerity/sha-rnn/blob/218d748022dbcf32d50bbbb4d151a9b6de3f8bba/model.py#L53</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Transformer</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1706.03762">Attention Is All You Need</a></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">GPT1</span></small></b></td>
      <td></td>
      <td></td>
      <td><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Let's build GPT: from scratch, in code, spelled out.</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">GPT2</span></small></b></td>
      <td></td>
      <td></td>
      <td><a href="https://www.youtube.com/watch?v=l8pRSuU81PU">Let's reproduce GPT-2 (124M)</a></td>
    </tr>
  </table>
</div>



<hr style="border: 2px solid #ccc; margin: 10px 0;">
<div style="border: 2px solid #ccc; padding: 10px; border-radius: 5px;">
  <h3>CV(ì»´í“¨í„°ë¹„ì „)</h3>
  <table>
    <tr>
      <th>ë…¼ë¬¸ ì£¼ì œ</th>
      <th>ë…¼ë¬¸ ì›ë³¸</th>
      <th>ë¦¬ë·° ë° ìš”ì•½</th>
      <th>ì½”ë“œêµ¬í˜„</th>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">AlexNet</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1301.6770">ImageNet Classification with Deep Convolutional Neural Networks</a></td>
      <td><a href="https://drive.google.com/file/d/1XKBEXIAmFsMSHdHDSb66aVDcy7GYBz2E/view?usp=drive_link">AlexNet Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/01_AlexNet">AlexNet Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">VGG16</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></td>
      <td><a href="https://drive.google.com/file/d/178gguYXBiLk-Py_Q2er1W2MeGIpumzPs/view?usp=drive_link">VGG16 Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/02_VGG">VGG16 Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">RCNN</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a></td>
      <td><a href="https://drive.google.com/file/d/10J0nLU0GlfqUR3ye2egxsJMNKCpSJUii/view?usp=drive_link">RCNN Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/03_RCNN">RCNN Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">GoogleNet</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1409.4842">Going Deeper with Convolutions</a></td>
      <td><a href="https://drive.google.com/file/d/17kmkDdQAHk0BKV6poqz0O4Ct5uYMzQNP/view?usp=drive_link">GoogleNet Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/04_GoogleNet">GoogleNet Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">ResNet</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1512.03385">Deep Residual Learning for Image Recognition</a></td>
      <td><a href="https://drive.google.com/file/d/1EI43FJ5KeYGhKn90yiFClsjMJnC3V0td/view?usp=drive_link">ResNet Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/06_Resnet">ResNet Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Faster RCNN</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></td>
      <td><a href="https://drive.google.com/file/d/19DgB-HShOnho1M3SgPGqRYm-U9bCqytH/view?usp=drive_link">Faster RCNN Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/07_Faster_rcnn">Faster RCNN Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">GoogleNet V4</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1602.07261">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></td>
      <td><a href="https://drive.google.com/file/d/1t3_6xg5da9NB2vwrzjv4qa3T50wd87ch/view?usp=drive_link">GoogleNet V4 Review</a></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/08_GooglenetV4">GoogleNet V4 Code</a></td>
    </tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">SSD</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/1512.02325">SSD: Single Shot MultiBox Detector</a></td>
      <td></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/09_SSD">SSD Code</a></td>
    </tr>
    <tr>
    <tr>
  <td><b><small><span style="color:#FFFF99">DeepLab V3</span></small></b></td>
  <td><a href="https://arxiv.org/pdf/1706.05587">Rethinking Atrous Convolution for Semantic Image Segmentation</a></td>
  <td></td>
  <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/10_DeepLab%20V3">DeepLab V3 Code</a></td>
</tr>
<tr>
  <td><b><small><span style="color:#FFFF99">Sniper</span></small></b></td>
  <td><a href="https://arxiv.org/pdf/1805.09300">SNIPER: Efficient Multi-Scale Training</a></td>
  <td></td>
  <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/11_Sniper">Sniper Code</a></td>
</tr>
<tr>
  <td><b><small><span style="color:#FFFF99">YOLOv3</span></small></b></td>
  <td><a href="https://arxiv.org/pdf/1804.02767">YOLOv3: An Incremental Improvement</a></td>
  <td></td>
  <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/12_YoloV3">YOLOv3 Code</a></td>
</tr>
<tr>
  <td><b><small><span style="color:#FFFF99">EfficientNet</span></small></b></td>
  <td><a href="https://arxiv.org/pdf/1905.11946">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></td>
  <td></td>
  <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/13_EfficientNet">EfficientNet Code</a></td>
</tr>

  <td><b><small><span style="color:#FFFF99">ViT</span></small></b></td>
  <td><a href="https://arxiv.org/pdf/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></td>
  <td></td>
  <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/15_ViT">ViT Code</a></td>
</tr>
    <tr>
      <td><b><small><span style="color:#FFFF99">Stable Diffusion</span></small></b></td>
      <td><a href="https://arxiv.org/pdf/2112.10752">High-Resolution Image Synthesis with Latent Diffusion Models</a></td>
      <td></td>
      <td><a href="https://github.com/jyjnote/PaperWithCode/tree/main/05_CV/16_Stabledifusion">Stable Diffusion Code</a></td>
    </tr>
  </table>
</div>

