{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2SSsQMSknm2"
      },
      "source": [
        "#### ResNet18 모델 정의 및 인스턴스 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zpUcgk5xkgGZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "\n",
        "# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
        "\n",
        "        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
        "\n",
        "        self.shortcut = nn.Sequential() # identity인 경우\n",
        "        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x) # (핵심) skip connection\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ResNet 클래스 정의\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        # 64개의 3x3 필터(filter)를 사용\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ResNet18 함수 정의\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2]) # 두번씩 중첩되게 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCNacrgtktlr"
      },
      "source": [
        "#### 데이터셋(Dataset) 다운로드 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "referenced_widgets": [
            "c33e7c07bfc847efa64429ee4eb640db",
            "987ce5cdc16f4c568f979204fa7506f2",
            "0dea8eb11bbc4c779008942559cff4db",
            "0ec3fad637ae4f5d8f9aa3a84e2cd7bd",
            "ff98ccdfba314fe5a6d9e477c6d4bd4b",
            "a1d1034a83034942b9174d8a46447ef0",
            "516e46a6995e4c10b928f2dbbbdd005a",
            "1c9448bb0e7b4d4bb219f9313bff333f"
          ]
        },
        "id": "EmmQZ8p5kq_C",
        "outputId": "ae6624d1-332f-412c-b2fc-51141afb1520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:22<00:00, 7629017.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl1-47E7pHD_"
      },
      "source": [
        "#### 환경 설정 및 학습(Training) 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bhm_eVykk-Z8"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "learning_rate = 0.1\n",
        "file_name = 'resnet18_cifar10.pt'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\n[ Train epoch: %d ]' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        benign_outputs = net(inputs)\n",
        "        loss = criterion(benign_outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = benign_outputs.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('\\nCurrent batch:', str(batch_idx))\n",
        "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
        "            print('Current benign train loss:', loss.item())\n",
        "\n",
        "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
        "    print('Total benign train loss:', train_loss)\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\n[ Test epoch: %d ]' % epoch)\n",
        "    net.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss += criterion(outputs, targets).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('\\nTest accuarcy:', 100. * correct / total)\n",
        "    print('Test average loss:', loss / total)\n",
        "\n",
        "    state = {\n",
        "        'net': net.state_dict()\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/' + file_name)\n",
        "    print('Model Saved!')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    if epoch >= 150:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mv5z7CEMRrn"
      },
      "source": [
        "#### 학습(Training) 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFdh-H1MPf0c"
      },
      "source": [
        "* 대략 20번의 epoch 이후에도 85%가량의 test accuracy를 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4voLj7TKlaB1",
        "outputId": "76463b85-2f4f-4bc0-a945-c73cc669c67e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ Train epoch: 0 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.109375\n",
            "Current benign train loss: 2.3359787464141846\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.25\n",
            "Current benign train loss: 2.0220062732696533\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.3046875\n",
            "Current benign train loss: 1.9417760372161865\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.3515625\n",
            "Current benign train loss: 1.6970734596252441\n",
            "\n",
            "Total benign train accuarcy: 29.174\n",
            "Total benign train loss: 779.0739749670029\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "\n",
            "Test accuarcy: 39.71\n",
            "Test average loss: 0.017140730464458465\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.34375\n",
            "Current benign train loss: 1.7465533018112183\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.375\n",
            "Current benign train loss: 1.7160298824310303\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.4296875\n",
            "Current benign train loss: 1.5468950271606445\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.46875\n",
            "Current benign train loss: 1.480217695236206\n",
            "\n",
            "Total benign train accuarcy: 43.894\n",
            "Total benign train loss: 596.7377460002899\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "\n",
            "Test accuarcy: 44.13\n",
            "Test average loss: 0.015796691858768464\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.5859375\n",
            "Current benign train loss: 1.2525404691696167\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.578125\n",
            "Current benign train loss: 1.2128568887710571\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.46875\n",
            "Current benign train loss: 1.3320740461349487\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.5234375\n",
            "Current benign train loss: 1.2921574115753174\n",
            "\n",
            "Total benign train accuarcy: 54.216\n",
            "Total benign train loss: 495.43167424201965\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "\n",
            "Test accuarcy: 51.96\n",
            "Test average loss: 0.013307005071640015\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.53125\n",
            "Current benign train loss: 1.2112267017364502\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.6015625\n",
            "Current benign train loss: 1.1601594686508179\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.6171875\n",
            "Current benign train loss: 1.1242454051971436\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.578125\n",
            "Current benign train loss: 1.110314130783081\n",
            "\n",
            "Total benign train accuarcy: 62.54\n",
            "Total benign train loss: 409.89066058397293\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "\n",
            "Test accuarcy: 64.33\n",
            "Test average loss: 0.0103325807929039\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.671875\n",
            "Current benign train loss: 0.8967438340187073\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.6171875\n",
            "Current benign train loss: 0.9493043422698975\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.6953125\n",
            "Current benign train loss: 0.8437649011611938\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.625\n",
            "Current benign train loss: 0.9104169011116028\n",
            "\n",
            "Total benign train accuarcy: 69.12\n",
            "Total benign train loss: 341.91520005464554\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "\n",
            "Test accuarcy: 69.35\n",
            "Test average loss: 0.008782165384292603\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.7265625\n",
            "Current benign train loss: 0.7669467329978943\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.7109375\n",
            "Current benign train loss: 0.8149048686027527\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.65625\n",
            "Current benign train loss: 0.9608612656593323\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.6875\n",
            "Current benign train loss: 0.8697664737701416\n",
            "\n",
            "Total benign train accuarcy: 74.554\n",
            "Total benign train loss: 284.77113220095634\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "\n",
            "Test accuarcy: 74.66\n",
            "Test average loss: 0.00747501477599144\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.7734375\n",
            "Current benign train loss: 0.5953935980796814\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.4863283336162567\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.7890625\n",
            "Current benign train loss: 0.5675014853477478\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8046875\n",
            "Current benign train loss: 0.675150454044342\n",
            "\n",
            "Total benign train accuarcy: 77.62\n",
            "Total benign train loss: 249.4755286872387\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "\n",
            "Test accuarcy: 69.97\n",
            "Test average loss: 0.008972335541248322\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.7578125\n",
            "Current benign train loss: 0.6685659289360046\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.8125\n",
            "Current benign train loss: 0.4818641245365143\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8359375\n",
            "Current benign train loss: 0.5209972858428955\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.4974181652069092\n",
            "\n",
            "Total benign train accuarcy: 80.292\n",
            "Total benign train loss: 221.96393239498138\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "\n",
            "Test accuarcy: 76.1\n",
            "Test average loss: 0.007346044224500656\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.4940693974494934\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.8515625\n",
            "Current benign train loss: 0.46840956807136536\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8203125\n",
            "Current benign train loss: 0.5181412100791931\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.7890625\n",
            "Current benign train loss: 0.5411323308944702\n",
            "\n",
            "Total benign train accuarcy: 82.538\n",
            "Total benign train loss: 197.9605709016323\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "\n",
            "Test accuarcy: 80.02\n",
            "Test average loss: 0.0059631304532289505\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.3894282579421997\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.5244002342224121\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.4590005874633789\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.828125\n",
            "Current benign train loss: 0.5687443614006042\n",
            "\n",
            "Total benign train accuarcy: 83.626\n",
            "Total benign train loss: 183.0460203886032\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "\n",
            "Test accuarcy: 82.12\n",
            "Test average loss: 0.00521180626153946\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.78125\n",
            "Current benign train loss: 0.5149573087692261\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.45291006565093994\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.8984375\n",
            "Current benign train loss: 0.3543170392513275\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.84375\n",
            "Current benign train loss: 0.45548945665359497\n",
            "\n",
            "Total benign train accuarcy: 84.852\n",
            "Total benign train loss: 169.16058376431465\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "\n",
            "Test accuarcy: 83.75\n",
            "Test average loss: 0.004825710797309876\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 11 ]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      3\u001b[0m     adjust_learning_rate(optimizer, epoch)\n\u001b[1;32m----> 4\u001b[0m     train(epoch)\n\u001b[0;32m      5\u001b[0m     test(epoch)\n",
            "Cell \u001b[1;32mIn[3], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     22\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, to_child)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\hopio\\anaconda3\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# for epoch in range(0, 200):\n",
        "for epoch in range(0, 20):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dea8eb11bbc4c779008942559cff4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d1034a83034942b9174d8a46447ef0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff98ccdfba314fe5a6d9e477c6d4bd4b",
            "value": 1
          }
        },
        "0ec3fad637ae4f5d8f9aa3a84e2cd7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9448bb0e7b4d4bb219f9313bff333f",
            "placeholder": "​",
            "style": "IPY_MODEL_516e46a6995e4c10b928f2dbbbdd005a",
            "value": " 170500096/? [00:20&lt;00:00, 100483168.85it/s]"
          }
        },
        "1c9448bb0e7b4d4bb219f9313bff333f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516e46a6995e4c10b928f2dbbbdd005a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "987ce5cdc16f4c568f979204fa7506f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d1034a83034942b9174d8a46447ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33e7c07bfc847efa64429ee4eb640db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dea8eb11bbc4c779008942559cff4db",
              "IPY_MODEL_0ec3fad637ae4f5d8f9aa3a84e2cd7bd"
            ],
            "layout": "IPY_MODEL_987ce5cdc16f4c568f979204fa7506f2"
          }
        },
        "ff98ccdfba314fe5a6d9e477c6d4bd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
