{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _**GoogLeNet_voc2012**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. inception 모듈\n",
    "2. auxiliary classifier \n",
    "3. global average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs) -> None:\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj) -> None:\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch1 = ConvBlock(in_channels, n1x1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_channels, n3x3_reduce, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(n3x3_reduce, n3x3, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_channels, n5x5_reduce, kernel_size=1, stride=1, padding=0),\n",
    "            ConvBlock(n5x5_reduce, n5x5, kernel_size=5, stride=1, padding=2))\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_channels, pool_proj, kernel_size=1, stride=1, padding=0))\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x4 = self.branch4(x)\n",
    "        return torch.cat([x1, x2, x3, x4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionAux(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes) -> None:\n",
    "        super(InceptionAux, self).__init__()\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        self.conv = ConvBlock(in_channels, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, aux_logits=True, num_classes=1000) -> None:\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        assert aux_logits == True or aux_logits == False\n",
    "        self.aux_logits = aux_logits\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)\n",
    "        self.conv2 = ConvBlock(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv3 = ConvBlock(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n",
    "        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        #self.avgpool = nn.AvgPool2d(kernel_size=8, stride=1) # if output size error occurred, choice add padding=3 or use AdaptiveAvgPool2d like bewlo:\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "        if self.aux_logits:\n",
    "            self.aux1 = InceptionAux(512, num_classes)\n",
    "            self.aux2 = InceptionAux(528, num_classes)\n",
    "        else:\n",
    "            self.aux1 = None\n",
    "            self.aux2 = None\n",
    "\n",
    "    def transform_input(self, x: Tensor) -> Tensor:\n",
    "        x_R = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "        x_G = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "        x_B = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "        x = torch.cat([x_R, x_G, x_B], 1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.transform_input(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.a3(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.a4(x)\n",
    "        aux1: Optional[Tensor] = None\n",
    "        if self.aux_logits and self.training:\n",
    "            aux1 = self.aux1(x)\n",
    "\n",
    "        x = self.b4(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.d4(x)\n",
    "        aux2: Optional[Tensor] = None\n",
    "        if self.aux_logits and self.training:\n",
    "            aux2 = self.aux2(x)\n",
    "\n",
    "        x = self.e4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.a5(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1) # x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if self.aux_logits and self.training:\n",
    "            return aux1, aux2\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:28<00:00, 5892399.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "라벨: tensor([8, 5, 3, 7, 7, 6, 9, 9, 0, 9, 3, 4, 0, 4, 3, 1, 4, 8, 2, 4, 1, 1, 3, 6,\n",
      "        1, 5, 9, 7, 9, 5, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 이미지 변환 설정_224x224로 resize, 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# CIFAR-10 데이터셋 다운로드\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader 설정 / 배치사이즈 32\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 데이터셋의 첫 번째 이미지와 라벨 확인\n",
    "data_iter = iter(train_loader)  # DataLoader 객체를 반복 가능한 객체로 변환\n",
    "images, labels = next(data_iter)  # 첫 번째 배치를 가져오기\n",
    "\n",
    "# 라벨 출력\n",
    "print(\"라벨:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def train(model, train_loader, test_loader, num_epochs=10, learning_rate=0.001):\n",
    "    from tqdm import tqdm\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # CUDA 사용 가능하면 GPU 사용, 아니면 CPU 사용\n",
    "    model = model.to(device)  # 모델을 지정된 장치(GPU/CPU)로 이동\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()  # 다중 클래스 분류 손실 함수\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 모델 학습 및 검증\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()  # 모델을 학습 모드로 전환\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # 미니 배치 단위로 데이터를 불러옴\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # 입력 데이터를 모델에 통과시킴\n",
    "            if model.aux_logits:  # aux_logits가 True일 때\n",
    "                outputs = model(inputs)  # 보조 출력을 포함한 모델 통과\n",
    "                if isinstance(outputs, tuple):  # 모델이 튜플을 반환하면 보조 출력도 포함\n",
    "                    outputs, aux1 = outputs  # 보조 출력이 하나만 반환되는 경우\n",
    "                    aux1 = aux1.view(-1, 10)\n",
    "                    loss1 = criterion(aux1, targets)\n",
    "                    loss = criterion(outputs, targets) + 0.3 * loss1\n",
    "                else:  # 보조 출력을 하나만 반환할 경우\n",
    "                    outputs = outputs[0]  # 주 출력만 사용\n",
    "                    targets = targets.view(-1)  # (batch_size * height * width,)\n",
    "                    outputs = outputs.view(-1, 10)\n",
    "                    loss = criterion(outputs, targets)\n",
    "            else:  # aux_logits가 False일 때\n",
    "                outputs = model(inputs)\n",
    "                targets = targets.view(-1)  # (batch_size * height * width,)\n",
    "                outputs = outputs.view(-1, 10)  # (batch_size * height * width, num_classes)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            # 역전파 및 최적화\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # 검증 데이터로 성능 평가\n",
    "        evaluate(model, test_loader, device)\n",
    "\n",
    "# 검증 함수\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()  # 모델을 평가 모드로 전환\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 그라디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # 입력 데이터를 지정된 장치로 이동\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1, 10)  # (batch_size * height * width, num_classes)\n",
    "            targets = targets.view(-1)  # (batch_size * height * width,)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.8761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:21<12:12, 81.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 8.76%\n",
      "Epoch [2/10], Loss: 1.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:42<10:47, 80.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 9.60%\n",
      "Epoch [3/10], Loss: 1.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [04:03<09:29, 81.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 7.68%\n",
      "Epoch [4/10], Loss: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:24<08:05, 80.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.24%\n",
      "Epoch [5/10], Loss: 0.8024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [06:44<06:43, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.70%\n",
      "Epoch [6/10], Loss: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [08:03<05:20, 80.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.06%\n",
      "Epoch [7/10], Loss: 0.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [09:23<04:00, 80.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 8.81%\n",
      "Epoch [8/10], Loss: 0.5531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [10:46<02:42, 81.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.09%\n",
      "Epoch [9/10], Loss: 0.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [12:08<01:21, 81.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.26%\n",
      "Epoch [10/10], Loss: 0.4429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:31<00:00, 81.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 학습\n",
    "model = GoogLeNet(aux_logits=True, num_classes=10)  # CIFAR10에는 10개의 클래스를 사용합니다\n",
    "train(model, train_loader, test_loader, num_epochs=10, learning_rate=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
